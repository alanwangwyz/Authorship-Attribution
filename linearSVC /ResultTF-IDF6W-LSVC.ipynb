{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle, os, string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                              Tweet\n",
      "0        8746     @handle Let's try and catch up live next week!\n",
      "1        8746  Going to watch Grey's on the big screen - Thur...\n",
      "2        8746  @handle My pleasure Patrick....hope you are well!\n",
      "3        8746  @handle Hi there! Been traveling a lot and lot...\n",
      "4        8746  RT @handle Looking to Drink Clean & Go Green? ...\n",
      "5        8746  RT @handle: Ft. Hood officials confirm the 2 o...\n",
      "6        8746  RT @handle: Mickey Mouse is Getting a Make Ove...\n",
      "7        8746           @handle How did u get the invite Justin?\n",
      "8        8746  @handle I think I am still a good friend of he...\n",
      "9        8746  @handle I remember! I am fine - how are u? Wha...\n",
      "10       8746     @handle That's great - good for the coach!!!!!\n",
      "11       8746  @handle I don't want to picture u sitting on i...\n",
      "12       8746  @handle D- Thanks for the RTs....are you going...\n",
      "13       8746           @handle Grrr....you must be going crazy!\n",
      "14       8746  @handle Hi there - just catching up from my tr...\n",
      "15       8746  RT @handle: If you're looking for some great l...\n",
      "16       8746  RT @handle: Retailers who aren’t engaging cust...\n",
      "17       8746  RT @handle: Director of Global Brand Marketing...\n",
      "18       8746  Still in car....want to jump out....45 minutes...\n",
      "19       8746  RT @handle: \"Only surround yourself with peopl...\n",
      "20       8746  @handle wish I could but 24/7 w stu's family t...\n",
      "21       8746  RT @handle: Help us help MusiCares! Vote for C...\n",
      "22       8746                     @handle yum!!!! Save me some!!\n",
      "23       8746  RT @handle: Gratitude is the sign of noble sou...\n",
      "24       8746           @handle I don't think I know what it is!\n",
      "25       8746  RT @handle: @handle Just found you via @handle...\n",
      "26       8746  RT @handle: RT @handle: Travelling for the Hol...\n",
      "27       8746       Just entering ohio - special hi to @handle!!\n",
      "28       8746  @handle well we agree on one food thing friend...\n",
      "29       8746                                @handle only 1!!!!!\n",
      "...       ...                                                ...\n",
      "328902   1319                                            @handle\n",
      "328903   1319  @handle Please add me to the #awsms09 afterpar...\n",
      "328904   1319  @handle great party last night...met some tale...\n",
      "328905   1319  Alta Phoenix Lofts #1 Phoenix!!!!! Congrats to...\n",
      "328906   9235                You manage things; you lead people.\n",
      "328907   9235  Not to know is bad; not to wish to know is worse.\n",
      "328908   9235  That there should one man die ignorant who had...\n",
      "328909   9235                       Will is character in action.\n",
      "328910   9235     What the mind dwells upon, the body acts upon.\n",
      "328911   9235      Success as I see it, is a result, not a goal.\n",
      "328912   9235  All generalizations are false, including this ...\n",
      "328913   9235  It is the province of knowledge to speak and i...\n",
      "328914   9235  A leader, once convinced that a particular cou...\n",
      "328915   9235  You can not make excuses and money at the same...\n",
      "328916   4357  Henry Brothers Electronics, Inc. to Participat...\n",
      "328917   4357  TechInsights' ESC UK Event Showcases Leading C...\n",
      "328918   4357  DEMOfall 09 Announces Lineup of Emerging Techn...\n",
      "328919   4357  AFP Hosts Symposium on Essentials for Doing Bu...\n",
      "328920   4357  AlertEnterprise Wins ASIS Accolades 2009 Secur...\n",
      "328921   4357  Andrews International Introduces New Methodolo...\n",
      "328922   4357  Innovation Strong Despite Recession: Human Res...\n",
      "328923   4357  VideoIQ and Milestone Systems Partner to Deliv...\n",
      "328924   4357  Phoenix Technologies to Showcase Cutting Edge ...\n",
      "328925   4357  AnyDATA's APT-210 Tracking Device Measures Att...\n",
      "328926   4357  Samplify Systems Announces Distribution Agreem...\n",
      "328927   4357  Steelbox Demonstrates Open Video Framework wit...\n",
      "328928   4357  Small Businesses Rely on Sage to Help Them Rid...\n",
      "328929   4357  TimeSight Systems™ Announces Next-Generation P...\n",
      "328930   4357  Diebold Makes Its Leading Monitoring Solutions...\n",
      "328931   4357  GVI Security Solutions to Introduce AutoIP™ VM...\n",
      "\n",
      "[328932 rows x 2 columns]\n",
      "                                                   Tweet\n",
      "0      Some people say that rappers don’t have feelin...\n",
      "1      Do you know how to tweet on a Blackberry 8830?...\n",
      "2            \"Yoga is the cessation of mind.\" -Patanjali\n",
      "3      @handle Well, with my millions of dollars, a f...\n",
      "4      Cambria hotels free guide http://hotels.izigot...\n",
      "5      May the force of Jesus be with you http://ff.i...\n",
      "6                             YEAH! It's finally Monday!\n",
      "7      Martin Laird won in Las Vegas last week with a...\n",
      "8      Joe's Crab Shack Fundraiser benefitting the Sa...\n",
      "9      i hate my self-portrait painting, I don't know...\n",
      "10     FREE system to generate leads! http://bit.ly/1...\n",
      "11     Life is tough. But Jesus softens it. Work with...\n",
      "12     @handle What is really tragic is the amount of...\n",
      "13     @handle Christine Lahti, she is going to be ar...\n",
      "14     RT @handle: @handle Does Twitter special inclu...\n",
      "15     hello my lovely's..let's get it!! @handle @han...\n",
      "16     New Blog Post! @handle's top fashion week pick...\n",
      "17     Control your diet by drinking plenty of water,...\n",
      "18     rt @handle 20 breathtaking realistic CG portra...\n",
      "19     @handle only plays german speed techno @handle...\n",
      "20     @handle yes please!!! what's your week looking...\n",
      "21                                      Hey chic @handle\n",
      "22     CleanTech's Ten Clean Technology Predictions f...\n",
      "23     5 of the Best Free and Open Source CD/DVD Writ...\n",
      "24     Check out the November edition of Factory Dire...\n",
      "25     lmfao! RT @handle @handle yea but without the ...\n",
      "26     RT @handle \"Your future is spotless, The only ...\n",
      "27     #Ad Really good site for community building #t...\n",
      "28                     Love getting my glow on in miami!\n",
      "29              Hardesty's spin move=badass. Give him 6!\n",
      "...                                                  ...\n",
      "35407  RT @handle Confrontation leads to solutions.: ...\n",
      "35408  \"no talking rule\" in effect for the Raider gam...\n",
      "35409                                   @handle Will do!\n",
      "35410  2034 Bobwhite Lane, Santa Cruz, CA 95065 - pre...\n",
      "35411  @handle I think there's a shot. Figgins. Polan...\n",
      "35412  Stand Up To Cancer!! Andrew McMahon of @handle...\n",
      "35413                @handle You are very welcome, Mark.\n",
      "35414  Vegas stereotype: 6 Asian girls stumbling by d...\n",
      "35415                   Red, red wine. Stay close to me.\n",
      "35416  Should health care workers be required to get ...\n",
      "35417  just joined a video chat with 2 other people a...\n",
      "35418  Celebrated 30 days sobriety n 10 pounds lost w...\n",
      "35419  @handle I never read the book! They have the c...\n",
      "35420  I just got an email from an affiliate of Sterl...\n",
      "35421     Meeting hubby for lunch-unexpected surprise :)\n",
      "35422                                       @handle LMAO\n",
      "35423  @handle yess OOO! I'm back in the lab cooking ...\n",
      "35424  Spent the afternoon taking care of a sick sist...\n",
      "35425                 searching for social media experts\n",
      "35426  The results are in ... see who won the Battle ...\n",
      "35427  RT @handle: @handle It always amazes me when s...\n",
      "35428  How To Get A Google Wave Account http://bit.ly...\n",
      "35429  Think spring: It's time to plan your garden ht...\n",
      "35430          Working in the villages tonight. Text me!\n",
      "35431  omg, Jimmy Choo is coming out with a line for ...\n",
      "35432  NCAA Football Odds - West Virginia at Cincinna...\n",
      "35433              @handle My favorite color!! Congrats!\n",
      "35434  It's not a simple matter to let others know wh...\n",
      "35435  Funny. The \"Smoke N Drank\" track off of In a M...\n",
      "35436                                   @handle Sup hun?\n",
      "\n",
      "[35437 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = None\n",
    "test_data = None\n",
    "\n",
    "def load_data():\n",
    "    global train_data, test_data\n",
    "    train_data = pd.read_csv('train_tweets.txt', delimiter=\"\\t\", header = None, quoting=csv.QUOTE_NONE)\n",
    "    test_data = pd.read_csv('test_tweets_unlabeled.txt', delimiter=\"\\t\", header = None, quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "load_data()\n",
    "train_data.columns = ['label','Tweet']\n",
    "test_data.columns = ['Tweet']\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9297\n"
     ]
    }
   ],
   "source": [
    "### computing the number of label\n",
    "numLabel = train_data['label'].unique()\n",
    "print(len(numLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 60000)\n",
    "allData = train_data['Tweet'].values.tolist() + test_data['Tweet'].values.tolist()\n",
    "bowAllData = vectorizer.fit_transform(allData) \n",
    "train_tagged = vectorizer.get_feature_names()\n",
    "# print (bow_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "# train_bow = bow[:328195, :]\n",
    "# xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train_data['label'], test_size=0.2)\n",
    "# lsvc=LinearSVC()\n",
    "# lsvc.fit(xtrain_bow, ytrain)\n",
    "# prediction = lsvc.predict_proba(xvalid_bow)\n",
    "# predictLabel = lsvc.predict(xvalid_bow)\n",
    "# print(lsvc.predict(xvalid_bow))\n",
    "lentrain = len(train_data)\n",
    "\n",
    "# Separate back into training and test sets.\n",
    "train = bowAllData[:lentrain]  \n",
    "test = bowAllData[lentrain:]\n",
    "# print (train)\n",
    "# print (test)\n",
    "#trainLabel = str(train_data['label'].unique())\n",
    "#print(\"label=\"+str(train_data['label'].unique()))\n",
    "#print(lreg.classes_) \n",
    "# ==========================\n",
    "lsvc=LinearSVC()\n",
    "lsvc.fit(train, train_data['label']) # training the model\n",
    " \n",
    "# trainPrediction = lsvc.predict_proba(test) # predicting on the validation set\n",
    "\n",
    "prediction = lsvc.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, filepath):\n",
    "    save_documents = open(filepath, 'wb')\n",
    "    pickle.dump(data, save_documents, protocol = 4)\n",
    "    save_documents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "cannot serialize a bytes object larger than 4 GiB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f966bd2fcb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf6WLSVC.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-74781db8a473>\u001b[0m in \u001b[0;36msave_pickle\u001b[0;34m(data, filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msave_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msave_documents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot serialize a bytes object larger than 4 GiB"
     ]
    }
   ],
   "source": [
    "save_pickle(lsvc, os.path.join('tfidf6WLSVC.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Predicted\n",
      "1          1       6778\n",
      "2          2       8119\n",
      "3          3       6492\n",
      "4          4       8894\n",
      "5          5       8297\n",
      "6          6       4273\n",
      "7          7       1130\n",
      "8          8       8646\n",
      "9          9        476\n",
      "10        10       9390\n",
      "11        11        640\n",
      "12        12       1624\n",
      "13        13       1071\n",
      "14        14       4897\n",
      "15        15       5565\n",
      "16        16       4426\n",
      "17        17       4450\n",
      "18        18       1698\n",
      "19        19        391\n",
      "20        20       8058\n",
      "21        21       8031\n",
      "22        22         25\n",
      "23        23       7022\n",
      "24        24       8704\n",
      "25        25       8250\n",
      "26        26        346\n",
      "27        27       5227\n",
      "28        28       8739\n",
      "29        29       5807\n",
      "30        30       2491\n",
      "...      ...        ...\n",
      "35408  35408       1606\n",
      "35409  35409       6148\n",
      "35410  35410       1463\n",
      "35411  35411       4397\n",
      "35412  35412       7170\n",
      "35413  35413       8720\n",
      "35414  35414       7265\n",
      "35415  35415       8275\n",
      "35416  35416       4335\n",
      "35417  35417       5004\n",
      "35418  35418       2188\n",
      "35419  35419       9429\n",
      "35420  35420       9953\n",
      "35421  35421       9492\n",
      "35422  35422       9038\n",
      "35423  35423       6500\n",
      "35424  35424       3830\n",
      "35425  35425       4254\n",
      "35426  35426       1717\n",
      "35427  35427       7760\n",
      "35428  35428       9771\n",
      "35429  35429       5076\n",
      "35430  35430       7594\n",
      "35431  35431        460\n",
      "35432  35432       1040\n",
      "35433  35433       8142\n",
      "35434  35434       6411\n",
      "35435  35435       7140\n",
      "35436  35436       1108\n",
      "35437  35437       2511\n",
      "\n",
      "[35437 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data['Predicted'] = prediction\n",
    "submission = test_data[['Predicted']]\n",
    "submission.index = np.arange(1, len(submission) + 1)\n",
    "submission['Id'] = submission.index\n",
    "\n",
    "columnsTitles=[\"Id\",\"Predicted\"]\n",
    "submission=submission.reindex(columns=columnsTitles)\n",
    "submission.to_csv('ResultTFIDF6WLSVN.csv',index=0)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Predicted     Id\n",
      "1           6778      0\n",
      "2           3409      1\n",
      "3           6492      2\n",
      "4           6463      3\n",
      "5           8297      4\n",
      "6           4273      5\n",
      "7           1130      6\n",
      "8           3387      7\n",
      "9            476      8\n",
      "10          4637      9\n",
      "11           640     10\n",
      "12          1624     11\n",
      "13          4191     12\n",
      "14          4897     13\n",
      "15          5565     14\n",
      "16          7173     15\n",
      "17          4450     16\n",
      "18          1698     17\n",
      "19           391     18\n",
      "20          8058     19\n",
      "21          4775     20\n",
      "22            25     21\n",
      "23          7022     22\n",
      "24          8704     23\n",
      "25          8250     24\n",
      "26           346     25\n",
      "27          5227     26\n",
      "28          8739     27\n",
      "29          5807     28\n",
      "30          4893     29\n",
      "...          ...    ...\n",
      "35408       2724  35407\n",
      "35409       9887  35408\n",
      "35410       1463  35409\n",
      "35411       4397  35410\n",
      "35412       7170  35411\n",
      "35413       6672  35412\n",
      "35414       7265  35413\n",
      "35415         42  35414\n",
      "35416       2728  35415\n",
      "35417       8204  35416\n",
      "35418       8645  35417\n",
      "35419       6596  35418\n",
      "35420       8273  35419\n",
      "35421       9492  35420\n",
      "35422       9038  35421\n",
      "35423       6500  35422\n",
      "35424       8338  35423\n",
      "35425       4254  35424\n",
      "35426       1717  35425\n",
      "35427       7760  35426\n",
      "35428       9771  35427\n",
      "35429       5076  35428\n",
      "35430       7594  35429\n",
      "35431       1782  35430\n",
      "35432       4026  35431\n",
      "35433       3003  35432\n",
      "35434       6411  35433\n",
      "35435       7140  35434\n",
      "35436       2688  35435\n",
      "35437       2511  35436\n",
      "\n",
      "[35437 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data['Predicted'] = prediction\n",
    "submission = test_data[['Predicted']]\n",
    "# submission['Id'] = submission.index\n",
    "# submission.index = np.arange(1, len(submission) + 1)\n",
    "\n",
    "\n",
    "\n",
    "# submission = pd.write_csv('ResultBOW5W.csv', names = ['Id', 'Predicted'])\n",
    "submission.to_csv('ResultBOW7W.csv',index=0)\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
